{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN =  'My API Token'\n",
    "HEADERS = {'Authorization' : f'token {TOKEN}'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = []\n",
    "page = 1\n",
    "while True:\n",
    "    url = f'https://api.github.com/search/users?q=location:Chicago+followers:>100&page={page}'\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    data = response.json()\n",
    "    users.extend(data['items'])\n",
    "    if 'next' not in response.links:\n",
    "        break\n",
    "    page +=1\n",
    "#users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = users[0]\n",
    "a = first.get('login')\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each user URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user = pd.DataFrame(columns=['login','name','company','location','email','hireable','bio','public_repos','followers','following','created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in users:\n",
    "    l1=[]\n",
    "    a = i.get('login')\n",
    "    url = f\"https://api.github.com/users/{a}\"\n",
    "    a = requests.get(url, headers= HEADERS).json()\n",
    "    l1 = [a['login'],a['name'],a['company'],a['location'],a['email'],a['hireable'],a['bio'],a['public_repos'],a['followers'],a['following'],a['created_at']]\n",
    "    df_user = pd.concat([pd.DataFrame([l1], columns=df_user.columns), df_user], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user['company'] = (df_user['company'].str.strip().str.lstrip('@').str.upper())\n",
    "df_user = df_user.fillna('null')\n",
    "df_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user.to_csv('users.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for repository data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_repos = pd.DataFrame(columns=['login','full_name','created_at','stargazers_count','watchers_count','language','has_projects','has_wiki','license_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in users:\n",
    "    l2=[]\n",
    "    user_login = j.get('login')\n",
    "    url_r = f\"https://api.github.com/users/{user_login}/repos\"\n",
    "    b = requests.get(url_r, headers= HEADERS).json()\n",
    "    for k in b:\n",
    "        l2 = [user_login,k['full_name'],k['created_at'],k['stargazers_count'],k['watchers_count'],k['language'],k['has_projects'],k['has_wiki']]\n",
    "        if k['license'] == None:\n",
    "            l2.append('null')\n",
    "        else:\n",
    "            l2.append(k['license']['name'])\n",
    "        df_repos = pd.concat([pd.DataFrame([l2], columns=df_repos.columns), df_repos], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_r = f\"https://api.github.com/users/{user_login}/repos\"\n",
    "b = requests.get(url_r, headers= HEADERS).json()\n",
    "b[1]['license']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_repos = df_repos.fillna('null')\n",
    "df_repos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_repos.to_csv('repositories.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1: Who are the top 5 users in Chicago with the highest number of followers? List their login in order, comma-separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_repos has a 'followers' column and a 'location' column.\n",
    "# First, filter the DataFrame for users located in Chicago\n",
    "chicago_users = df_user[df_user['location'].str.contains(\"Chicago\", na=False)]\n",
    "\n",
    "# Sort by the number of followers in descending order\n",
    "top_chicago_users = chicago_users.sort_values(by='followers', ascending=False).head(5)\n",
    "\n",
    "# Get the logins of the top 5 users\n",
    "top_user_logins = top_chicago_users['login'].tolist()\n",
    "\n",
    "# Print the logins as a comma-separated string\n",
    "print(', '.join(top_user_logins))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_users = df_user.sort_values(by='followers', ascending=False).head(5)\n",
    "top_user_logins = top_users['login'].tolist()\n",
    "print(', '.join(top_user_logins))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_logins = list(df_user.sort_values(by='followers', ascending=False).head()['login'])\n",
    "for login in popular_logins:\n",
    "    print(login, end=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earliest_users = df_user.sort_values(by='created_at').head(5)\n",
    "earliest_user_logins = earliest_users['login'].tolist()\n",
    "print(', '.join(earliest_user_logins))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming repo_df has a 'license_name' column\n",
    "# Filter out rows with missing licenses\n",
    "filtered_licenses = df_repos[df_repos['license_name'].notnull()]\n",
    "\n",
    "# Count the occurrences of each license\n",
    "license_counts = filtered_licenses['license_name'].value_counts()\n",
    "\n",
    "# Get the top 3 most popular licenses\n",
    "top_licenses = license_counts.head(5)\n",
    "\n",
    "# Print the license names as a comma-separated string\n",
    "print(', '.join(top_licenses.index))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_users has a 'company' column\n",
    "# Filter out null values in the 'company' column\n",
    "filtered_companies = df_user['company'].dropna()\n",
    "\n",
    "# Count the occurrences of each company\n",
    "company_counts = filtered_companies.value_counts()\n",
    "\n",
    "# Get the top 2 companies\n",
    "top_companies = company_counts.head(2)\n",
    "\n",
    "# Print the result\n",
    "print(\"Top 2 companies where developers work:\")\n",
    "for company, count in top_companies.items():\n",
    "    print(f\"{company}: {count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_users has a 'language' column\n",
    "# Count the occurrences of each programming language, ignoring null values\n",
    "language_counts = df_repos['language'].dropna().value_counts()\n",
    "\n",
    "# Get the most popular programming language\n",
    "most_popular_count = language_counts.head(2)\n",
    "\n",
    "# Print the result\n",
    "print(f\"The most popular programming language is: {most_popular_language} (Count: {most_popular_count})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_users has 'created_at' and 'language' columns\n",
    "\n",
    "# Convert 'created_at' to datetime if it's not already\n",
    "df_repos['created_at'] = pd.to_datetime(df_repos['created_at'], errors='coerce')\n",
    "\n",
    "# Filter users who joined after 2020\n",
    "users_after_2020 = df_repos[df_repos['created_at'] > '2020-12-31']\n",
    "\n",
    "# Count the occurrences of each programming language, ignoring null values\n",
    "language_counts = users_after_2020['language'].dropna().value_counts()\n",
    "\n",
    "# Get the top 3 most popular programming languages\n",
    "top_languages = language_counts.head(3)\n",
    "\n",
    "# Print the results\n",
    "print(\"Top 3 programming languages among users who joined after 2020:\")\n",
    "for language, count in top_languages.items():\n",
    "    print(f\"{language}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_repo has 'language' and 'stargazers_count' columns\n",
    "\n",
    "# Group by 'language' and calculate the average stargazers_count\n",
    "average_stars_per_language = df_repos.groupby('language')['stargazers_count'].mean()\n",
    "\n",
    "# Get the language with the highest average\n",
    "highest_average_language = average_stars_per_language.idxmax()\n",
    "highest_average_count = average_stars_per_language.max()\n",
    "\n",
    "# Print the result\n",
    "print(f\"The language with the highest average number of stars per repository is: {highest_average_language} (Average Stars: {highest_average_count})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_users has 'followers' and 'following' columns\n",
    "# Calculate leader_strength\n",
    "df_user['leader_strength'] = df_user['followers'] / (1 + df_user['following'])\n",
    "\n",
    "# Get the top 5 users by leader_strength\n",
    "top_leaders = df_user.nlargest(5, 'leader_strength')\n",
    "\n",
    "# List their logins in order, comma-separated\n",
    "top_logins = ', '.join(top_leaders['login'].tolist())\n",
    "\n",
    "# Print the result\n",
    "print(f\"Top 5 users in terms of leader_strength: {top_logins}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_users has 'followers' and 'public_repos' columns\n",
    "\n",
    "# Calculate the correlation between followers and public repositories\n",
    "correlation = df_user['followers'].corr(df_user['public_repos'])\n",
    "\n",
    "# Print the result\n",
    "print(f\"The correlation between the number of followers and the number of public repositories is: {correlation}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df_users has 'followers' and 'public_repos' columns\n",
    "# Prepare the data\n",
    "X = df_user[['public_repos']]  # Independent variable (public repositories)\n",
    "y = df_user['followers']        # Dependent variable (followers)\n",
    "\n",
    "# Remove any rows with NaN values\n",
    "X = X.dropna()\n",
    "y = y[X.index]  # Keep only the indices of X that are valid\n",
    "\n",
    "# Create and fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Get the slope (coefficient)\n",
    "slope = model.coef_[0]\n",
    "\n",
    "# Print the result\n",
    "print(f\"The regression slope of followers on public repositories is: {slope}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NaN values in 'following':\", df_user['following'].isna().sum())\n",
    "\n",
    "# Filter users with hireable = True\n",
    "hireable_users = df_user[df_user['hireable'] == True]\n",
    "print(\"Number of hireable users:\", len(hireable_users))\n",
    "\n",
    "# Filter users with hireable = False\n",
    "non_hireable_users = df_user[df_user['hireable'] == False]\n",
    "print(\"Number of non-hireable users:\", len(non_hireable_users))\n",
    "\n",
    "# Calculate average following for hireable users, ignoring NaN\n",
    "average_hireable = hireable_users['following'].mean()\n",
    "print(\"Average following for hireable users:\", average_hireable)\n",
    "\n",
    "# Calculate average following for non-hireable users, ignoring NaN\n",
    "average_non_hireable = non_hireable_users['following'].mean()\n",
    "print(\"Average following for non-hireable users:\", average_non_hireable)\n",
    "\n",
    "# Calculate the difference, handling NaN\n",
    "difference = (average_hireable if not pd.isna(average_hireable) else 0) - \\\n",
    "             (average_non_hireable if not pd.isna(average_non_hireable) else 0)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Difference in average following (hireable - non-hireable): {difference}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quesition 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Sample DataFrame (replace this with your actual df_users DataFrame)\n",
    "# df_users = pd.read_csv('your_file.csv')\n",
    "\n",
    "# Step 1: Calculate the word count of the bio\n",
    "# Using fillna to avoid errors with NaN values in the bio column\n",
    "df_user['bio_word_count'] = df_user['bio'].fillna('').apply(lambda x: len(x.split()))\n",
    "\n",
    "# Step 2: Prepare the data for regression\n",
    "# Ensure to drop any rows where followers or bio_word_count are NaN\n",
    "df_user = df_user.dropna(subset=['followers', 'bio_word_count'])\n",
    "\n",
    "X = df_user[['bio_word_count']]  # Independent variable (bio word count)\n",
    "y = df_user['followers']          # Dependent variable (followers)\n",
    "\n",
    "# Step 3: Create and fit the model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Get the slope (coefficient)\n",
    "slope = model.coef_[0]\n",
    "\n",
    "# Print the result\n",
    "print(f\"The regression slope of followers on bio word count is: {slope}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming repos_df is your DataFrame containing repository data\n",
    "# repos_df = pd.read_csv('your_repos_file.csv')\n",
    "\n",
    "# Step 1: Convert the created_at column to datetime\n",
    "df_repos['created_at'] = pd.to_datetime(df_repos['created_at'])\n",
    "\n",
    "# Step 2: Filter for weekend days (Saturday = 5, Sunday = 6)\n",
    "df_repos['day_of_week'] = df_repos['created_at'].dt.dayofweek\n",
    "weekend_repos = df_repos[df_repos['day_of_week'].isin([5, 6])]\n",
    "\n",
    "# Step 3: Group by user login and count the number of repositories\n",
    "repos_count = weekend_repos.groupby('login').size().reset_index(name='repo_count')\n",
    "\n",
    "# Step 4: Sort by repo_count in descending order and get the top 5\n",
    "top_weekend_users = repos_count.sort_values(by='repo_count', ascending=False).head(5)\n",
    "\n",
    "# Step 5: Get the logins as a comma-separated string\n",
    "top_users_logins = ', '.join(top_weekend_users['login'].tolist())\n",
    "\n",
    "# Print the result\n",
    "print(f\"Top 5 users who created the most repositories on weekends: {top_users_logins}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df_users is your DataFrame containing user data\n",
    "# df_users = pd.read_csv('your_users_file.csv')\n",
    "\n",
    "# Step 1: Calculate the fraction of users with email when hireable=True\n",
    "hireable_users = df_users[df_users['hireable'] == True]\n",
    "fraction_hireable_with_email = hireable_users['email'].notna().mean()\n",
    "\n",
    "# Step 2: Calculate the fraction of users with email for the rest (hireable=False)\n",
    "non_hireable_users = df_users[df_users['hireable'] != True]\n",
    "fraction_non_hireable_with_email = non_hireable_users['email'].notna().mean()\n",
    "\n",
    "# Step 3: Calculate the difference and round to 3 decimal places\n",
    "difference = round(fraction_hireable_with_email - fraction_non_hireable_with_email, 3)\n",
    "\n",
    "# Print the result\n",
    "print(f\"The difference in the fraction of users with email is: {difference}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df_users is your DataFrame containing user data\n",
    "# df_users = pd.read_csv('your_users_file.csv')\n",
    "\n",
    "# Step 1: Filter out null strings and empty names, then trim whitespace\n",
    "df_users = df_user[(df_user['name'].notna()) & (df_user['name'] != 'null') & (df_user['name'] != '')].copy()\n",
    "\n",
    "# Step 2: Trim whitespace\n",
    "df_users['name'] = df_users['name'].str.strip()\n",
    "\n",
    "# Step 3: Extract surnames (last word of the name)\n",
    "df_users['surname'] = df_users['name'].apply(lambda x: x.split()[-1])\n",
    "\n",
    "# Step 4: Count occurrences of each surname\n",
    "surname_counts = df_users['surname'].value_counts()\n",
    "\n",
    "# Step 5: Determine the maximum count and filter the surnames\n",
    "max_count = surname_counts.max()\n",
    "most_common_surnames = surname_counts[surname_counts == max_count].index.tolist()\n",
    "\n",
    "# Step 6: Sort the surnames alphabetically and join them into a comma-separated string\n",
    "most_common_surnames.sort()\n",
    "result = ', '.join(most_common_surnames)\n",
    "\n",
    "# Print the result\n",
    "print(f\"The most common surname(s): {result}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
